# Indexing with MinHash Bloom Trees

CTBQ: if you include inverted index, maybe the title should change?

\chaptermark {MHBT}

## Abstract

## Introduction

Searching for matches in large collection of datasets is not viable when hundreds of thousands of
them are available,
especially if they are partitioned and not all present at the same place.

CTBQ: Additional points to raise: in-memory representation of sketches may be too big (!!), goal here is on disk storage/low minimum memory for "extremely large data" situation. Also/in addition, want ability to do incremental loading of things. Note we are not talking here about situations where the indices themselves are too big to download, could maybe include forward pointer to chp4.

Note, in this chapter you could also include distinction in performance between SBT and LCA DB, to whit: large scaled works well with LCA (small DB, ~tolerable memory, load all at once, then quite fast) but low scaled may work (much) better with SBT.

### Hierarchical index

<!-- 'k-mer aggregative methods in (marchet 2019)' -->

Bloofi [@crainiceanu_bloofi:_2015] is a hierarchical index structure that
extends the Bloom Filter basic query to collections of Bloom Filters.
Instead of calculating the union of all Bloom Filters in the collection
(which would allow answering if an element is present in any of them)
it defines a tree structure where the original Bloom Filters are leaves,
and internal nodes are the union of all the Bloom Filters in their subtrees.
Searching is based on a breadth-first search,
with pruning when no matches are found at an internal level.
Bloofi can also be partitioned in a network,
with network nodes containing a subtree of the original tree and only being
accessed if the search requires it.

The Sequence Bloom Tree [@solomon_fast_2016] adapts Bloofi for genomic contexts,
rephrasing the problem as experiment discovery:
given a query sequence $Q$ and a threshold $\theta$,
which experiments contain at least $\theta$ of the original query $Q$?
Experiments are encoded in Bloom Filters containing the $k$-mer composition of transcriptomes,
and queries are transcripts.

Further developments focused on clustering similar datasets to prune search
early [@sun_allsome_2017] and developing more efficient representations for the
internal nodes [@solomon_improved_2017] [@harris_improved_2018] to use less
storage space and memory.

### Inverted index

<!-- 'color- aggregative methods in (marchet 2019)' -->

An inverted index is a mapping from words in a text back to its location inside
the text.
An example is the index in the back of a book,
containing a list of topics and in which page they are present.
Information retrieval system use inverted index to find the occurrences of
words in a text [@ziviani:2000].

In the signature collection indexing case,
the inverted index is a map of all hashes in the collection back to
the signature from where they originated.
Just as words can appear more than once in a text,
hashes show up in more than one signature,
so the inverted index maps a hash to a list of signatures IDs.

kraken has a similar index,
but uses a taxonomic ID for each dataset.
Datasets can share the same ID (taxon),
if they belong to the same taxon.
Moreover,
if a hash is present in more than one dataset
kraken also reduces the list of taxons to the lowest common ancestor (LCA),
which leads to reduced memory usage.
[@dasko:2018] explores how this LCA approach leads to decreased precision and sensitivity over time,
since more datasets are added to reference databases and the chance of a k-mer being present
in multiple datasets increases.

Efficient storage of the list of signatures IDs can also be achieved via representation of the list as colors,
where a color can represent one dataset or multiple datasets (if a hash is present in many of them).
Mantis [@pandey_mantis:_2017] uses this hash to color mapping
(and an auxiliary color table) to achieve reduced memory usage.

## Results

### Efficient containment and similarity searches

#### Index construction and updating

resources (time, cpu, mem)
<!--

- sourmash indices benefit from more data. Inverted index

-->

#### Querying

<!--
COST (cost of single thread)
-->

### CAMI challenges

Critical Assessment of Metagenome Intepretation (CAMI) is a community-driven initiative,
and brings together tool developers to create standard and reproducible
benchmarking methods.
It is divided in three big groups:
assembly,
binning and profiling.

Since there is a standard output format that tools need to implement,
performance comparisons can be
<!--

Intro: what is CAMI, what it provides:
- challenges provide gold standards (what is expected to be in the sample)
- standardized tools for profiling performance comparisons (OPAL)

-->

#### CAMI 1 (low, medium, high)

<!--
- Already published, but results are for older/outdated tools
- still a good benchmark (because gold standards are available)
- low and medium datasets have viruses, which are not in sourmash indices
-->

#### CAMI 2 mouse gut toy challenge

<!--
- new CAMI challenges, with short and long reads (pacbio)
- toy challenge is calibration: gold standard available
- CAMI provides results for other tools

CAMI 2 refseq database also doesn't have viruses...

- sourmash gather:
-->

## Discussion

### Limitations

<!--
Viruses (scaled minhash too small).
  mash screen solves this by going for sensitivity (at the cost of precision),
  possible solution: scaled+num hashes, but would only allow mash screen-like method


-->

### Future directions

<!--
- Better localization in SBT
   * or go full HowDe SBT
- batch_insert for SBT, insert_one for Inverted Index
- Other indices
  * Fundamentally a scaled minhash is a subset of the k-mer composition of a
  dataset, so any index from https://www.biorxiv.org/content/10.1101/866756v1
  ("Data structures based on k-mers for querying large collections of sequencing datasets")
  can be used to scale,
  and given that gather is defined over a collection of signatures the indices
  can also be used to improve gather performance.
- gather assigns hashes to best matches ("winner-takes-all"). Other approaches
  will be needed to disambiguate matches further
- sourmash is currently single threaded, but that's an implementation detail.
  Parallel queries are possible (in a shared read-only index)
-->

### Summary/Conclusion

## Methods

### Mathematical foundations

### Implementation

sourmash is implemented in Rust for the core performance-critical functionality,
and exposes a C API that is wrapped in Python for higher-level features.
This includes a Python API for interactive use,
as well as a command-line interface for more traditional bioinformatics workflows.

### Experiments
